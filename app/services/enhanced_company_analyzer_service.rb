require 'net/http'
require 'json'

class EnhancedCompanyAnalyzerService
  def initialize(company_name)
    @company_name = company_name
    @api_key = ENV['OPENAI_API_KEY']
    @scraper = CompanyWebScraperService.new(company_name)
  end

  def perform_enhanced_analysis
    Rails.logger.info "ğŸš€ Starting enhanced analysis with web scraping for: #{@company_name}"
    
    # 1ë‹¨ê³„: ì›¹ í¬ë¡¤ë§ìœ¼ë¡œ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘
    scraped_data = @scraper.scrape_all
    
    # 2ë‹¨ê³„: í¬ë¡¤ë§ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê° ì„¹ì…˜ ë¶„ì„
    results = {}
    threads = []
    errors = []
    
    # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ê° ì„¹ì…˜ ë¶„ì„
    threads << Thread.new do
      begin
        results[:executive_summary] = generate_executive_summary(scraped_data)
      rescue => e
        errors << "Executive Summary: #{e.message}"
        results[:executive_summary] = nil
      end
    end
    
    threads << Thread.new do
      begin
        results[:company_overview] = analyze_company_overview(scraped_data)
      rescue => e
        errors << "Company Overview: #{e.message}"
        results[:company_overview] = nil
      end
    end
    
    threads << Thread.new do
      begin
        results[:industry_market] = analyze_industry_market(scraped_data)
      rescue => e
        errors << "Industry Market: #{e.message}"
        results[:industry_market] = nil
      end
    end
    
    threads << Thread.new do
      begin
        results[:hiring_strategy] = analyze_hiring_strategy(scraped_data)
      rescue => e
        errors << "Hiring Strategy: #{e.message}"
        results[:hiring_strategy] = nil
      end
    end
    
    threads << Thread.new do
      begin
        results[:job_preparation] = analyze_job_preparation(scraped_data)
      rescue => e
        errors << "Job Preparation: #{e.message}"
        results[:job_preparation] = nil
      end
    end
    
    threads << Thread.new do
      begin
        results[:competitor_comparison] = analyze_competitor_comparison(scraped_data)
      rescue => e
        errors << "Competitor Comparison: #{e.message}"
        results[:competitor_comparison] = nil
      end
    end
    
    threads << Thread.new do
      begin
        results[:consultant_advice] = generate_consultant_advice(scraped_data)
      rescue => e
        errors << "Consultant Advice: #{e.message}"
        results[:consultant_advice] = nil
      end
    end
    
    # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
    threads.each(&:join)
    
    # ì—ëŸ¬ ë¡œê¹…
    if errors.any?
      Rails.logger.error "Enhanced Analysis Errors: #{errors.join(', ')}"
    end
    
    # ê²°ê³¼ ì¡°í•©
    {
      executive_summary: results[:executive_summary] || "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
      company_overview: results[:company_overview] || "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
      industry_market: results[:industry_market] || "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
      hiring_strategy: results[:hiring_strategy] || "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
      job_preparation: results[:job_preparation] || "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
      competitor_comparison: results[:competitor_comparison] || "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
      consultant_advice: results[:consultant_advice] || "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
      metadata: {
        analysis_date: Time.current,
        analysis_version: '5.0',
        methodology: 'Web Scraping + GPT-4 Enhanced Analysis',
        data_sources: extract_data_sources(scraped_data),
        model_used: ENV['OPENAI_MODEL'] || 'gpt-4',
        parallel_processing: true,
        parallel_threads: 7,
        web_scraping: true,
        errors: errors
      },
      scraped_data: scraped_data # ì›ë³¸ í¬ë¡¤ë§ ë°ì´í„°ë„ í¬í•¨
    }
  end

  private

  def extract_data_sources(scraped_data)
    sources = []
    sources << "JobKorea" if scraped_data[:recruitment].any?
    sources << "Saramin" if scraped_data[:basic_info][:companyName].present?
    sources << "Naver News" if scraped_data[:news].any?
    sources << "JobPlanet" if scraped_data[:reviews].any?
    sources
  end

  def generate_executive_summary(scraped_data)
    # í¬ë¡¤ë§ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ë³€í™˜
    data_summary = prepare_data_summary(scraped_data)
    
    prompt = <<~PROMPT
      ğŸ“Œ ê¸°ì—…ë¶„ì„ ìš”ì•½ (ì›¹ í¬ë¡¤ë§ ë°ì´í„° ê¸°ë°˜)
      ê¸°ì—…ëª…: #{@company_name}
      í˜„ì¬ ë‚ ì§œ: #{Time.current.strftime('%Yë…„ %mì›”')}
      
      **ì‹¤ì œ ìˆ˜ì§‘ëœ ë°ì´í„°:**
      #{data_summary}
      
      ë„ˆëŠ” ê²½ë ¥ 15ë…„ì˜ ì·¨ì—… ì»¨ì„¤í„´íŠ¸ë‹¤. 
      ìœ„ì˜ ì‹¤ì œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì·¨ì—… ì¤€ë¹„ìƒì´ #{@company_name}ì— ì§€ì›í•˜ê¸° ì „ ë°˜ë“œì‹œ ì•Œì•„ì•¼ í•  í•µì‹¬ ì •ë³´ë¥¼ ìš”ì•½í•˜ë¼.
      ë°ì´í„°ê°€ ì—†ëŠ” ë¶€ë¶„ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³  "ì •ë³´ ì—†ìŒ"ìœ¼ë¡œ í‘œì‹œí•˜ë¼.
      
      ## ğŸ“Š í•œ ëˆˆì— ë³´ëŠ” #{@company_name}
      
      ### ğŸ¯ ì§€ì›ìê°€ ê¼­ ì•Œì•„ì•¼ í•  3ê°€ì§€
      1. [ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ í˜„ì¬ ìƒí™©]
      2. [ì±„ìš© ê³µê³  ë¶„ì„ ê¸°ë°˜ ì¸ì¬ìƒ]
      3. [ë‰´ìŠ¤ ë¶„ì„ ê¸°ë°˜ ìµœì‹  ë™í–¥]
      
      ### ğŸ’¡ ì±„ìš© íŠ¸ë Œë“œ (ì‹¤ì œ ì±„ìš©ê³µê³  ê¸°ë°˜)
      â€¢ í˜„ì¬ ì±„ìš© ì¤‘ì¸ í¬ì§€ì…˜: [ì‹¤ì œ ê³µê³  ë°ì´í„°]
      â€¢ ì£¼ë ¥ ì±„ìš© ì§ë¬´: [ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ì§ë¬´]
      â€¢ ìš”êµ¬ ê²½ë ¥: [ì‹ ì…/ê²½ë ¥ ë¹„ìœ¨]
      â€¢ ê·¼ë¬´ ì§€ì—­: [ì‹¤ì œ ë°ì´í„°]
      
      ### ğŸ“° ìµœì‹  ë‰´ìŠ¤ ìš”ì•½
      [ìˆ˜ì§‘ëœ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ 3ê°œ ìš”ì•½]
      
      ### âš¡ ì§€ì› ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸
      â–¡ ìµœê·¼ ë‰´ìŠ¤ì˜ í•µì‹¬ ì´ìŠˆë¥¼ íŒŒì•…í–ˆëŠ”ê°€?
      â–¡ í˜„ì¬ ì±„ìš© ì¤‘ì¸ ì§ë¬´ì™€ ë‚´ ì—­ëŸ‰ì´ ë§¤ì¹­ë˜ëŠ”ê°€?
      â–¡ ê¸°ì—… ë¦¬ë·°ì˜ ì¥ë‹¨ì ì„ í™•ì¸í–ˆëŠ”ê°€?
      
      ì‹¤ì œ ë°ì´í„°ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í•˜ë¼. ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ë¡ ì€ ë°°ì œí•˜ë¼.
    PROMPT

    call_gpt_api(prompt, max_tokens: 1500)
  end

  def analyze_company_overview(scraped_data)
    data_summary = prepare_data_summary(scraped_data)
    
    prompt = <<~PROMPT
      ê¸°ì—…ëª…: #{@company_name}
      í˜„ì¬ ë‚ ì§œ: #{Time.current.strftime('%Yë…„ %mì›”')}
      
      **ìˆ˜ì§‘ëœ ê¸°ì—… ì •ë³´:**
      #{data_summary}
      
      ## 1. ê¸°ì—… ê°œìš” & í˜„í™© (ì›¹ í¬ë¡¤ë§ ë°ì´í„° ê¸°ë°˜)
      
      ìœ„ì˜ ì‹¤ì œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ì—… ê°œìš”ë¥¼ ì‘ì„±í•˜ë¼.
      
      ### ê¸°ë³¸ ì •ë³´
      â€¢ ê¸°ì—…ëª…: #{scraped_data[:basic_info][:name] || scraped_data[:basic_info][:companyName] || @company_name}
      â€¢ ì—…ì¢…: #{scraped_data[:basic_info][:industry] || "ì •ë³´ ì—†ìŒ"}
      â€¢ ê·œëª¨: #{scraped_data[:basic_info][:size] || scraped_data[:basic_info][:employees] || "ì •ë³´ ì—†ìŒ"}
      â€¢ ëŒ€í‘œ: #{scraped_data[:basic_info][:ceo] || "ì •ë³´ ì—†ìŒ"}
      â€¢ ìœ„ì¹˜: #{scraped_data[:basic_info][:address] || "ì •ë³´ ì—†ìŒ"}
      â€¢ í™ˆí˜ì´ì§€: #{scraped_data[:basic_info][:website] || "ì •ë³´ ì—†ìŒ"}
      
      ### ìµœê·¼ ë™í–¥ (ë‰´ìŠ¤ ë¶„ì„)
      [ìˆ˜ì§‘ëœ ë‰´ìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœê·¼ 3ê°œì›” ì£¼ìš” ì´ìŠˆ ì •ë¦¬]
      
      ### ì±„ìš© í˜„í™©
      [ì‹¤ì œ ì±„ìš©ê³µê³  ë°ì´í„° ê¸°ë°˜ í˜„ì¬ ì±„ìš© ë™í–¥]
      
      ### ê¸°ì—… í‰íŒ (ë¦¬ë·° ë°ì´í„°)
      [JobPlanet ë“±ì—ì„œ ìˆ˜ì§‘í•œ í‰ì ê³¼ ë¦¬ë·° ìš”ì•½]
      
      **[ì·¨ì—… TIP]**
      â†’ ì‹¤ì œ ë°ì´í„°ë¥¼ ë³´ë©´ #{@company_name}ëŠ” í˜„ì¬ [í•µì‹¬ íŠ¹ì§•]ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.
      ìê¸°ì†Œê°œì„œì—ì„œëŠ” ì´ëŸ¬í•œ ì‹¤ì œ ìƒí™©ì„ ë°˜ì˜í•œ ì§€ì›ë™ê¸°ë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
      
      ë°ì´í„°ê°€ ì—†ëŠ” ë¶€ë¶„ì€ "ì •ë³´ ìˆ˜ì§‘ ë¶ˆê°€"ë¡œ ëª…ì‹œí•˜ê³ , ì¶”ì¸¡í•˜ì§€ ë§ˆë¼.
    PROMPT

    call_gpt_api(prompt, max_tokens: 2000)
  end

  def analyze_industry_market(scraped_data)
    data_summary = prepare_data_summary(scraped_data)
    
    prompt = <<~PROMPT
      ê¸°ì—…ëª…: #{@company_name}
      
      **ìˆ˜ì§‘ëœ ë°ì´í„°:**
      #{data_summary}
      
      ## 2. ì‹œì¥ ë¶„ì„ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
      
      ### ë‰´ìŠ¤ì—ì„œ ë‚˜íƒ€ë‚œ ì‚°ì—… íŠ¸ë Œë“œ
      [ìˆ˜ì§‘ëœ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ì—…ê³„ ë™í–¥ íŒŒì•…]
      
      ### ì±„ìš© ì‹œì¥ ë¶„ì„
      â€¢ ì±„ìš© ê·œëª¨: [ì‹¤ì œ ê³µê³  ìˆ˜ ê¸°ë°˜]
      â€¢ ì£¼ìš” ì§ë¬´: [ê°€ì¥ ë§ì´ ì±„ìš©í•˜ëŠ” í¬ì§€ì…˜]
      â€¢ ìš”êµ¬ ì—­ëŸ‰: [ê³µê³ ì—ì„œ ì¶”ì¶œí•œ í‚¤ì›Œë“œ]
      â€¢ ê²½ë ¥ ìš”êµ¬ì‚¬í•­: [ì‹ ì…/ê²½ë ¥ ë¶„í¬]
      
      ### ê²½ìŸ í™˜ê²½ (ë‰´ìŠ¤ ì–¸ê¸‰ ê¸°ì¤€)
      [ë‰´ìŠ¤ì—ì„œ í•¨ê»˜ ì–¸ê¸‰ëœ ê²½ìŸì‚¬ ë¶„ì„]
      
      ### ê¸°íšŒì™€ ìœ„ê¸° ìš”ì¸
      **ê¸°íšŒ ìš”ì¸** (ë‰´ìŠ¤/ê³µê³  ë¶„ì„)
      â€¢ [ì‹¤ì œ ë°ì´í„°ì—ì„œ ë„ì¶œí•œ ê¸°íšŒ]
      
      **ìœ„ê¸° ìš”ì¸** (ë‰´ìŠ¤ ë¶„ì„)
      â€¢ [ë¶€ì •ì  ë‰´ìŠ¤ë‚˜ ì´ìŠˆ]
      
      ìˆ˜ì§‘ëœ ë°ì´í„°ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ê³ , ì—†ëŠ” ì •ë³´ëŠ” ëª…ì‹œí•˜ë¼.
    PROMPT

    call_gpt_api(prompt, max_tokens: 2000)
  end

  def analyze_hiring_strategy(scraped_data)
    # ì±„ìš© ê³µê³  ë°ì´í„° ì •ë¦¬
    job_data = extract_job_data(scraped_data)
    
    prompt = <<~PROMPT
      ê¸°ì—…ëª…: #{@company_name}
      
      **ì‹¤ì œ ì±„ìš© ë°ì´í„°:**
      #{job_data.to_json}
      
      ## 3. ì±„ìš© ì „ëµ ë¶„ì„ (ì‹¤ì œ ê³µê³  ê¸°ë°˜)
      
      ### í˜„ì¬ ì±„ìš© ì¤‘ì¸ í¬ì§€ì…˜
      #{format_job_listings(scraped_data[:recruitment])}
      
      ### ì±„ìš© íŒ¨í„´ ë¶„ì„
      â€¢ ì´ ì±„ìš© ê³µê³  ìˆ˜: #{scraped_data[:recruitment].size}
      â€¢ ì£¼ìš” ì§ë¬´ ë¶„í¬: [ë°ì´í„° ê¸°ë°˜ ë¶„ì„]
      â€¢ ê²½ë ¥ ìš”êµ¬ì‚¬í•­: [ì‹ ì…/ê²½ë ¥ ë¹„ìœ¨]
      â€¢ ê·¼ë¬´ ì§€ì—­: [ì§€ì—­ë³„ ë¶„í¬]
      â€¢ ë§ˆê°ì¼ íŒ¨í„´: [ê¸´ê¸‰/ì¼ë°˜ ì±„ìš© ë¶„ì„]
      
      ### í•µì‹¬ ìš”êµ¬ ì—­ëŸ‰ (ê³µê³  í…ìŠ¤íŠ¸ ë¶„ì„)
      [ì‹¤ì œ ê³µê³ ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš” í‚¤ì›Œë“œì™€ ì—­ëŸ‰]
      
      ### ê¸°ì—… ë¦¬ë·° ê¸°ë°˜ ì¡°ì§ë¬¸í™”
      â€¢ í‰ì : #{scraped_data[:reviews].first&.dig(:rating) || "ì •ë³´ ì—†ìŒ"}
      â€¢ ì¶”ì²œìœ¨: #{scraped_data[:reviews].first&.dig(:recommendation) || "ì •ë³´ ì—†ìŒ"}
      â€¢ í‰ê·  ì—°ë´‰: #{scraped_data[:reviews].first&.dig(:salary) || "ì •ë³´ ì—†ìŒ"}
      
      ### ì§€ì› ì „ëµ
      **ì„œë¥˜ ì „í˜• ëŒ€ë¹„**
      â€¢ í•„ìˆ˜ í‚¤ì›Œë“œ: [ê³µê³ ì—ì„œ ì¶”ì¶œí•œ í‚¤ì›Œë“œ]
      â€¢ ìš°ëŒ€ ì‚¬í•­: [ì‹¤ì œ ìš°ëŒ€ì‚¬í•­ ì •ë¦¬]
      
      **ë©´ì ‘ ëŒ€ë¹„**
      â€¢ ì˜ˆìƒ ì§ˆë¬¸: [ê¸°ì—… ì´ìŠˆ ê¸°ë°˜]
      â€¢ ì¤€ë¹„ í¬ì¸íŠ¸: [ë‰´ìŠ¤ì™€ ê³µê³  ì—°ê³„]
      
      ì‹¤ì œ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ë¼.
    PROMPT

    call_gpt_api(prompt, max_tokens: 3000)
  end

  def analyze_job_preparation(scraped_data)
    prompt = <<~PROMPT
      ê¸°ì—…ëª…: #{@company_name}
      
      **ìˆ˜ì§‘ëœ ë°ì´í„° ìš”ì•½:**
      â€¢ ì±„ìš© ê³µê³  ìˆ˜: #{scraped_data[:recruitment].size}
      â€¢ ìµœì‹  ë‰´ìŠ¤ ìˆ˜: #{scraped_data[:news].size}
      â€¢ ê¸°ì—… ë¦¬ë·° ë°ì´í„°: #{scraped_data[:reviews].any? ? "ìˆìŒ" : "ì—†ìŒ"}
      
      ## 4. ì·¨ì—… ì¤€ë¹„ ì „ëµ (ë°ì´í„° ê¸°ë°˜)
      
      ### ìê¸°ì†Œê°œì„œ ì‘ì„± ê°€ì´ë“œ
      
      **í•„ìˆ˜ í¬í•¨ í‚¤ì›Œë“œ** (ì±„ìš©ê³µê³  ë¶„ì„)
      #{extract_keywords_from_jobs(scraped_data[:recruitment])}
      
      **ìµœì‹  ì´ìŠˆ ë°˜ì˜** (ë‰´ìŠ¤ ë¶„ì„)
      #{extract_key_news_points(scraped_data[:news])}
      
      ### ë©´ì ‘ ì¤€ë¹„ í¬ì¸íŠ¸
      
      **ì˜ˆìƒ ì§ˆë¬¸** (ë°ì´í„° ê¸°ë°˜)
      1. ìµœê·¼ ë‰´ìŠ¤: "ìš°ë¦¬ íšŒì‚¬ì˜ [ìµœì‹  ì´ìŠˆ]ì— ëŒ€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ì‹œë‚˜ìš”?"
      2. ì§ë¬´ ì´í•´: "í˜„ì¬ ì±„ìš© ì¤‘ì¸ [ì£¼ìš” ì§ë¬´]ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì—­ëŸ‰ì€?"
      3. ì§€ì› ë™ê¸°: "ì™œ ì§€ê¸ˆ ì‹œì ì— ìš°ë¦¬ íšŒì‚¬ì— ì§€ì›í–ˆë‚˜ìš”?"
      
      ### í¬íŠ¸í´ë¦¬ì˜¤ ì¤€ë¹„
      [ì±„ìš© ê³µê³ ì˜ ìš”êµ¬ì‚¬í•­ì— ë§ì¶˜ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ì œì•ˆ]
      
      ### ì°¨ë³„í™” ì „ëµ
      â€¢ ìµœì‹  ë‰´ìŠ¤ ìˆ™ì§€: [í•µì‹¬ ì´ìŠˆ 3ê°œ]
      â€¢ ì±„ìš© íŠ¸ë Œë“œ íŒŒì•…: [í˜„ì¬ ì§‘ì¤‘ ì±„ìš© ë¶„ì•¼]
      â€¢ ê¸°ì—… ë‹ˆì¦ˆ ì´í•´: [ê³µê³ ì—ì„œ ë„ì¶œí•œ ë‹ˆì¦ˆ]
      
      ë°ì´í„°ì— ê·¼ê±°í•œ ì‹¤ìš©ì  ì¡°ì–¸ë§Œ ì œê³µí•˜ë¼.
    PROMPT

    call_gpt_api(prompt, max_tokens: 2500)
  end

  def analyze_competitor_comparison(scraped_data)
    prompt = <<~PROMPT
      ê¸°ì—…ëª…: #{@company_name}
      
      ## 5. ê²½ìŸ ë¶„ì„ (ë‰´ìŠ¤ ë°ì´í„° ê¸°ë°˜)
      
      ### ë‰´ìŠ¤ì—ì„œ ì–¸ê¸‰ëœ ê´€ë ¨ ê¸°ì—…
      [ë‰´ìŠ¤ ë¶„ì„ì„ í†µí•´ íŒŒì•…í•œ ê²½ìŸì‚¬ë‚˜ í˜‘ë ¥ì‚¬]
      
      ### #{@company_name}ì˜ í¬ì§€ì…˜
      â€¢ ì‹œì¥ ìœ„ì¹˜: [ë‰´ìŠ¤ í†¤ ë¶„ì„]
      â€¢ ì£¼ìš” ê°•ì : [ê¸ì •ì  ë‰´ìŠ¤ ë¶„ì„]
      â€¢ ê°œì„  ì˜ì—­: [ì´ìŠˆë‚˜ ê³¼ì œ]
      
      ### ì±„ìš© ê²½ìŸë ¥
      â€¢ ì±„ìš© ê·œëª¨: #{scraped_data[:recruitment].size}ê°œ í¬ì§€ì…˜
      â€¢ ë¦¬ë·° í‰ì : #{scraped_data[:reviews].first&.dig(:rating) || "ì •ë³´ ì—†ìŒ"}
      â€¢ ê¸‰ì—¬ ìˆ˜ì¤€: #{scraped_data[:reviews].first&.dig(:salary) || "ì •ë³´ ì—†ìŒ"}
      
      ### ì°¨ë³„í™” í¬ì¸íŠ¸
      [ì‹¤ì œ ë°ì´í„°ì—ì„œ ë„ì¶œí•œ ì°¨ë³„ì ]
      
      ìˆ˜ì§‘ ê°€ëŠ¥í•œ ë°ì´í„°ë§Œìœ¼ë¡œ ë¶„ì„í•˜ë¼.
    PROMPT

    call_gpt_api(prompt, max_tokens: 2000)
  end

  def generate_consultant_advice(scraped_data)
    # í•µì‹¬ ë°ì´í„° ìš”ì•½
    key_insights = {
      total_jobs: scraped_data[:recruitment].size,
      recent_news: scraped_data[:news].first(3).map { |n| n[:title] },
      company_rating: scraped_data[:reviews].first&.dig(:rating),
      main_keywords: extract_all_keywords(scraped_data)
    }
    
    prompt = <<~PROMPT
      ê¸°ì—…ëª…: #{@company_name}
      
      **í•µì‹¬ ì¸ì‚¬ì´íŠ¸:**
      #{key_insights.to_json}
      
      ## 6. ì»¨ì„¤í„´íŠ¸ ìµœì¢… ì¡°ì–¸
      
      ### ğŸ¯ ë°ì´í„° ê¸°ë°˜ í•µì‹¬ ì „ëµ
      
      **1. ì§€ê¸ˆ ì§€ì›í•´ì•¼ í•˜ëŠ” ì´ìœ **
      â€¢ í˜„ì¬ ì±„ìš© ê·œëª¨: #{key_insights[:total_jobs]}ê°œ í¬ì§€ì…˜
      â€¢ ìµœì‹  ì´ìŠˆ: [ë‰´ìŠ¤ ê¸°ë°˜ ë¶„ì„]
      â€¢ ì‹œì¥ ìƒí™©: [ë°ì´í„° ê¸°ë°˜ íŒë‹¨]
      
      **2. ì°¨ë³„í™”ëœ ì§€ì› ì „ëµ**
      â€¢ í•µì‹¬ í‚¤ì›Œë“œ í™œìš©: #{key_insights[:main_keywords].first(5).join(', ') if key_insights[:main_keywords]}
      â€¢ ìµœì‹  ì´ìŠˆ ì–¸ê¸‰: í•„ìˆ˜
      â€¢ ë°ì´í„° ê¸°ë°˜ ì§€ì›ë™ê¸°: ê°•ë ¥ ì¶”ì²œ
      
      **3. ì£¼ì˜ì‚¬í•­**
      â€¢ ê³¼ì¥ëœ ì •ë³´ ì£¼ì˜ (ì‹¤ì œ ë°ì´í„°ì™€ ëŒ€ì¡°)
      â€¢ ìµœì‹  ë‰´ìŠ¤ ë°˜ë“œì‹œ í™•ì¸
      â€¢ ì±„ìš© ê³µê³  ì„¸ë¶€ì‚¬í•­ ìˆ™ì§€
      
      ### ğŸ“‹ ì•¡ì…˜ í”Œëœ
      
      **ì¦‰ì‹œ ì‹¤í–‰ (ì˜¤ëŠ˜)**
      â–¡ #{@company_name} ìµœì‹  ë‰´ìŠ¤ 10ê°œ ì •ë…
      â–¡ í˜„ì¬ ì±„ìš©ê³µê³  ëª¨ë‘ ì €ì¥
      â–¡ ê¸°ì—… ë¦¬ë·° í™•ì¸
      
      **1ì£¼ì¼ ë‚´ ì™„ë£Œ**
      â–¡ ì±„ìš©ê³µê³  í‚¤ì›Œë“œ ë¶„ì„
      â–¡ ìì†Œì„œ ì´ˆì•ˆ ì‘ì„±
      â–¡ í¬íŠ¸í´ë¦¬ì˜¤ ì—…ë°ì´íŠ¸
      
      **ì§€ì› ì „ ìµœì¢… ì²´í¬**
      â–¡ ìµœì‹  ë‰´ìŠ¤ ì—…ë°ì´íŠ¸ í™•ì¸
      â–¡ ìì†Œì„œ í‚¤ì›Œë“œ ë§¤ì¹­ ê²€ì¦
      â–¡ ë©´ì ‘ ì˜ˆìƒì§ˆë¬¸ 10ê°œ ì¤€ë¹„
      
      ### ğŸ’¡ ì„±ê³µ í™•ë¥  ë†’ì´ê¸°
      
      í˜„ì¬ ë°ì´í„°ë¥¼ ë³´ë©´ #{@company_name}ëŠ”:
      1. [ê°€ì¥ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸]
      2. [ë‘ ë²ˆì§¸ ì¸ì‚¬ì´íŠ¸]
      3. [ì„¸ ë²ˆì§¸ ì¸ì‚¬ì´íŠ¸]
      
      ì´ë¥¼ í™œìš©í•œ ì§€ì› ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”.
      
      ì‹¤ì œ ë°ì´í„°ì— ê¸°ë°˜í•œ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ë§Œ ì œê³µí•˜ë¼.
    PROMPT

    call_gpt_api(prompt, max_tokens: 3000)
  end

  # Helper methods
  def prepare_data_summary(scraped_data)
    summary = []
    
    if scraped_data[:basic_info].any?
      summary << "**ê¸°ì—… ê¸°ë³¸ì •ë³´:**\n#{scraped_data[:basic_info].to_json}"
    end
    
    if scraped_data[:recruitment].any?
      summary << "**ì±„ìš© ê³µê³  (#{scraped_data[:recruitment].size}ê°œ):**"
      scraped_data[:recruitment].first(3).each do |job|
        summary << "- #{job[:title] || job[:position]}: #{job[:experience]}, #{job[:location]}"
      end
    end
    
    if scraped_data[:news].any?
      summary << "**ìµœì‹  ë‰´ìŠ¤ (#{scraped_data[:news].size}ê°œ):**"
      scraped_data[:news].first(3).each do |news|
        summary << "- #{news[:title]} (#{news[:date]})"
      end
    end
    
    if scraped_data[:reviews].any?
      summary << "**ê¸°ì—… ë¦¬ë·°:**\n#{scraped_data[:reviews].first.to_json}"
    end
    
    summary.join("\n\n")
  end

  def extract_job_data(scraped_data)
    {
      total_count: scraped_data[:recruitment].size,
      positions: scraped_data[:recruitment].map { |j| j[:title] || j[:position] }.compact,
      locations: scraped_data[:recruitment].map { |j| j[:location] }.compact.uniq,
      experience_levels: scraped_data[:recruitment].map { |j| j[:experience] }.compact.uniq
    }
  end

  def format_job_listings(jobs)
    return "í˜„ì¬ ì±„ìš© ì •ë³´ ì—†ìŒ" if jobs.empty?
    
    jobs.first(5).map do |job|
      "â€¢ #{job[:title] || job[:position]}: #{job[:experience]}, #{job[:location]}, #{job[:deadline]}"
    end.join("\n")
  end

  def extract_keywords_from_jobs(jobs)
    return "í‚¤ì›Œë“œ ì¶”ì¶œ ë¶ˆê°€" if jobs.empty?
    
    all_text = jobs.map { |j| "#{j[:title]} #{j[:position]}" }.join(" ")
    words = all_text.split(/\s+/).map(&:downcase)
    word_freq = words.each_with_object(Hash.new(0)) { |word, hash| hash[word] += 1 }
    
    word_freq.sort_by { |_, count| -count }
             .first(10)
             .map { |word, count| "â€¢ #{word} (#{count}íšŒ)" }
             .join("\n")
  end

  def extract_key_news_points(news)
    return "ìµœì‹  ë‰´ìŠ¤ ì—†ìŒ" if news.empty?
    
    news.first(3).map do |item|
      "â€¢ #{item[:title]} - #{item[:source]} (#{item[:date]})"
    end.join("\n")
  end

  def extract_all_keywords(scraped_data)
    all_text = []
    all_text << scraped_data[:recruitment].map { |j| "#{j[:title]} #{j[:position]}" }.join(" ")
    all_text << scraped_data[:news].map { |n| n[:title] }.join(" ")
    
    text = all_text.join(" ")
    words = text.split(/\s+/).map(&:downcase).reject { |w| w.length < 2 }
    
    word_freq = words.each_with_object(Hash.new(0)) { |word, hash| hash[word] += 1 }
    word_freq.sort_by { |_, count| -count }.first(20).map(&:first)
  end

  def call_gpt_api(prompt, max_tokens: 2500)
    require 'net/http'
    require 'json'
    
    uri = URI('https://api.openai.com/v1/chat/completions')
    http = Net::HTTP.new(uri.host, uri.port)
    http.use_ssl = true
    http.read_timeout = 180
    
    request = Net::HTTP::Post.new(uri)
    request['Authorization'] = "Bearer #{@api_key}"
    request['Content-Type'] = 'application/json'
    
    request.body = {
      model: ENV['OPENAI_MODEL'] || 'gpt-4',
      messages: [
        { 
          role: 'system', 
          content: 'ë‹¹ì‹ ì€ ì›¹ í¬ë¡¤ë§ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
          ì‹¤ì œ ë°ì´í„°ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ë©°, ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ë¡ ì€ ë°°ì œí•©ë‹ˆë‹¤.
          ë°ì´í„°ê°€ ì—†ëŠ” ë¶€ë¶„ì€ ëª…í™•íˆ "ì •ë³´ ì—†ìŒ"ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.' 
        },
        { role: 'user', content: prompt }
      ],
      temperature: 0.7,
      max_tokens: max_tokens
    }.to_json
    
    response = http.request(request)
    result = JSON.parse(response.body)
    
    if result['choices']
      result['choices'][0]['message']['content']
    else
      "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: #{result['error']&.dig('message')}"
    end
  rescue => e
    Rails.logger.error "GPT API Error: #{e.message}"
    "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: #{e.message}"
  end
end