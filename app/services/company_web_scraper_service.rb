require 'playwright'
require 'nokogiri'
require 'json'

class CompanyWebScraperService
  def initialize(company_name)
    @company_name = company_name
    @results = {
      basic_info: {},
      news: [],
      recruitment: [],
      reviews: [],
      financial: {},
      raw_data: []
    }
  end
  
  def scrape_all
    Rails.logger.info "ğŸŒ Starting web scraping for: #{@company_name}"
    
    Playwright.create(playwright_cli_executable_path: 'npx playwright') do |playwright|
      chromium = playwright.chromium
      browser = chromium.launch(headless: true)
      
      begin
        # ë³‘ë ¬ë¡œ ì—¬ëŸ¬ ì‚¬ì´íŠ¸ í¬ë¡¤ë§
        threads = []
        
        # 1. ì¡ì½”ë¦¬ì•„ í¬ë¡¤ë§
        threads << Thread.new do
          scrape_jobkorea(browser)
        rescue => e
          Rails.logger.error "JobKorea scraping error: #{e.message}"
        end
        
        # 2. ì‚¬ëŒì¸ í¬ë¡¤ë§
        threads << Thread.new do
          scrape_saramin(browser)
        rescue => e
          Rails.logger.error "Saramin scraping error: #{e.message}"
        end
        
        # 3. ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§
        threads << Thread.new do
          scrape_naver_news(browser)
        rescue => e
          Rails.logger.error "Naver news scraping error: #{e.message}"
        end
        
        # 4. ì¡í”Œë˜ë‹› ë¦¬ë·° í¬ë¡¤ë§
        threads << Thread.new do
          scrape_jobplanet(browser)
        rescue => e
          Rails.logger.error "JobPlanet scraping error: #{e.message}"
        end
        
        # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
        threads.each(&:join)
        
      ensure
        browser.close
      end
    end
    
    Rails.logger.info "âœ… Web scraping completed for: #{@company_name}"
    @results
  rescue => e
    Rails.logger.error "Web scraping failed: #{e.message}"
    @results[:error] = e.message
    @results
  end
  
  private
  
  def scrape_jobkorea(browser)
    Rails.logger.info "ğŸ“ Scraping JobKorea..."
    
    context = browser.new_context
    page = context.new_page
    
    # ì¡ì½”ë¦¬ì•„ì—ì„œ ê¸°ì—… ê²€ìƒ‰
    search_url = "https://www.jobkorea.co.kr/Search/?stext=#{URI.encode_www_form_component(@company_name)}"
    page.goto(search_url, wait_until: 'networkidle')
    
    # ê²€ìƒ‰ ê²°ê³¼ ëŒ€ê¸°
    page.wait_for_selector('.list-default', timeout: 10000) rescue nil
    
    # ì±„ìš©ê³µê³  ì •ë³´ ìˆ˜ì§‘
    job_listings = page.evaluate(<<~JS)
      Array.from(document.querySelectorAll('.list-default li')).slice(0, 5).map(item => ({
        title: item.querySelector('.title')?.innerText || '',
        company: item.querySelector('.name')?.innerText || '',
        location: item.querySelector('.loc')?.innerText || '',
        experience: item.querySelector('.exp')?.innerText || '',
        education: item.querySelector('.edu')?.innerText || '',
        deadline: item.querySelector('.date')?.innerText || '',
        url: item.querySelector('a')?.href || ''
      }))
    JS
    
    @results[:recruitment] = job_listings
    
    # ê¸°ì—… ì •ë³´ í˜ì´ì§€ë¡œ ì´ë™ ì‹œë„
    company_link = page.query_selector("a[href*='/company/']")
    if company_link
      company_link.click
      page.wait_for_load_state('networkidle')
      
      # ê¸°ì—… ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
      company_info = page.evaluate(<<~JS)
        {
          name: document.querySelector('.company-name')?.innerText || '',
          industry: document.querySelector('.industry')?.innerText || '',
          size: document.querySelector('.company-size')?.innerText || '',
          founded: document.querySelector('.founded-year')?.innerText || '',
          employees: document.querySelector('.employee-count')?.innerText || '',
          description: document.querySelector('.company-description')?.innerText || ''
        }
      JS
      
      @results[:basic_info].merge!(company_info)
    end
    
    context.close
  end
  
  def scrape_saramin(browser)
    Rails.logger.info "ğŸ“ Scraping Saramin..."
    
    context = browser.new_context
    page = context.new_page
    
    # ì‚¬ëŒì¸ì—ì„œ ê¸°ì—… ê²€ìƒ‰
    search_url = "https://www.saramin.co.kr/zf_user/search?searchword=#{URI.encode_www_form_component(@company_name)}&go=&flag=n&searchMode=1&searchType=search&search_done=y&search_optional_item=n"
    page.goto(search_url, wait_until: 'networkidle')
    
    # ê¸°ì—… ì •ë³´ íƒ­ í´ë¦­
    company_tab = page.query_selector("a[data-tab='company']")
    if company_tab
      company_tab.click
      page.wait_for_selector('.content_col', timeout: 5000) rescue nil
      
      # ê¸°ì—… ì •ë³´ ìˆ˜ì§‘
      company_data = page.evaluate(<<~JS)
        {
          companyName: document.querySelector('.company_nm')?.innerText || '',
          industry: document.querySelector('.industry')?.innerText || '',
          ceo: document.querySelector('.ceo')?.innerText || '',
          website: document.querySelector('.homepage')?.innerText || '',
          address: document.querySelector('.address')?.innerText || '',
          employees: document.querySelector('.employee')?.innerText || ''
        }
      JS
      
      @results[:basic_info].merge!(company_data)
    end
    
    # ì±„ìš© ì •ë³´ íƒ­ìœ¼ë¡œ ì´ë™
    recruit_tab = page.query_selector("a[data-tab='recruit']")
    if recruit_tab
      recruit_tab.click
      page.wait_for_selector('.recruit_list', timeout: 5000) rescue nil
      
      # ì±„ìš© ì •ë³´ ìˆ˜ì§‘
      recruit_data = page.evaluate(<<~JS)
        Array.from(document.querySelectorAll('.recruit_list .item')).slice(0, 5).map(item => ({
          position: item.querySelector('.job_tit')?.innerText || '',
          experience: item.querySelector('.career')?.innerText || '',
          education: item.querySelector('.education')?.innerText || '',
          location: item.querySelector('.work_place')?.innerText || '',
          deadline: item.querySelector('.deadlines')?.innerText || ''
        }))
      JS
      
      @results[:recruitment].concat(recruit_data) if recruit_data.any?
    end
    
    context.close
  end
  
  def scrape_naver_news(browser)
    Rails.logger.info "ğŸ“ Scraping Naver News..."
    
    context = browser.new_context
    page = context.new_page
    
    # ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰
    news_url = "https://search.naver.com/search.naver?where=news&query=#{URI.encode_www_form_component(@company_name)}"
    page.goto(news_url, wait_until: 'networkidle')
    
    # ë‰´ìŠ¤ ê²°ê³¼ ëŒ€ê¸°
    page.wait_for_selector('.news_area', timeout: 5000) rescue nil
    
    # ìµœê·¼ ë‰´ìŠ¤ ìˆ˜ì§‘ (ìµœëŒ€ 10ê°œ)
    news_data = page.evaluate(<<~JS)
      Array.from(document.querySelectorAll('.news_area')).slice(0, 10).map(item => ({
        title: item.querySelector('.news_tit')?.innerText || '',
        content: item.querySelector('.news_dsc')?.innerText || '',
        source: item.querySelector('.info_group .press')?.innerText || '',
        date: item.querySelector('.info_group span.info')?.innerText || '',
        url: item.querySelector('.news_tit')?.href || ''
      }))
    JS
    
    @results[:news] = news_data
    
    # ìµœì‹  ë‰´ìŠ¤ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
    if news_data.any?
      keywords = extract_keywords_from_news(news_data)
      @results[:basic_info][:recent_keywords] = keywords
    end
    
    context.close
  end
  
  def scrape_jobplanet(browser)
    Rails.logger.info "ğŸ“ Scraping JobPlanet..."
    
    context = browser.new_context
    page = context.new_page
    
    # ì¡í”Œë˜ë‹› ê²€ìƒ‰ (ë¡œê·¸ì¸ í•„ìš” ì—†ëŠ” ê³µê°œ ì •ë³´ë§Œ)
    search_url = "https://www.jobplanet.co.kr/search?query=#{URI.encode_www_form_component(@company_name)}"
    page.goto(search_url, wait_until: 'networkidle')
    
    # ê¸°ì—… ë¦¬ë·° ìš”ì•½ ì •ë³´ ìˆ˜ì§‘
    page.wait_for_selector('.company_card', timeout: 5000) rescue nil
    
    review_summary = page.evaluate(<<~JS)
      {
        rating: document.querySelector('.rate_point')?.innerText || '',
        reviewCount: document.querySelector('.review_count')?.innerText || '',
        salary: document.querySelector('.salary_info')?.innerText || '',
        recommendation: document.querySelector('.recommend_rate')?.innerText || ''
      }
    JS
    
    @results[:reviews] = [review_summary] if review_summary[:rating].present?
    
    context.close
  end
  
  def extract_keywords_from_news(news_data)
    # ë‰´ìŠ¤ ì œëª©ê³¼ ë‚´ìš©ì—ì„œ ìì£¼ ë‚˜ì˜¤ëŠ” í‚¤ì›Œë“œ ì¶”ì¶œ
    text = news_data.map { |n| "#{n[:title]} #{n[:content]}" }.join(" ")
    
    # ë¶ˆìš©ì–´ ì œê±°
    stopwords = %w[ì˜ ë¥¼ ì´ ê°€ ì€ ëŠ” ê³¼ ì™€ ìœ¼ë¡œ ì—ì„œ ì—ê²Œ ê¹Œì§€ ë¶€í„° ì²˜ëŸ¼ ë§Œí¼ ë³´ë‹¤]
    
    # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
    words = text.split(/\s+/)
                .map(&:downcase)
                .reject { |w| w.length < 2 || stopwords.include?(w) }
    
    word_freq = words.each_with_object(Hash.new(0)) { |word, hash| hash[word] += 1 }
    
    # ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ ë°˜í™˜
    word_freq.sort_by { |_, count| -count }
             .first(10)
             .map(&:first)
  end
  
  def clean_text(text)
    text.to_s.strip.gsub(/\s+/, ' ')
  end
end