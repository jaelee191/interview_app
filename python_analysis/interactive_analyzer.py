#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ëŒ€í™”í˜• ìì†Œì„œ ì‘ì„± ì§€ì›ì„ ìœ„í•œ NLP ë¶„ì„ ëª¨ë“ˆ
- ë‹µë³€ í’ˆì§ˆ í‰ê°€
- í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì—­ëŸ‰ ë§¤ì¹­
- STAR ê¸°ë²• ì¤€ìˆ˜ ì—¬ë¶€ ì²´í¬
- êµ¬ì²´ì„± ë° ì§„ì •ì„± í‰ê°€
"""

import json
import re
import sys
from typing import Dict, List, Tuple, Any
from collections import Counter

# numpyëŠ” ì„ íƒì ìœ¼ë¡œ ì‚¬ìš©
try:
    import numpy as np
    USE_NUMPY = True
except ImportError:
    USE_NUMPY = False

# í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„
try:
    from konlpy.tag import Okt
    USE_KONLPY = True
except ImportError:
    USE_KONLPY = False
    print("Warning: KoNLPy not installed. Using basic analysis.", file=sys.stderr)

class InteractiveAnalyzer:
    """ëŒ€í™”í˜• ìì†Œì„œ ë‹µë³€ ë¶„ì„ê¸°"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        if USE_KONLPY:
            self.okt = Okt()
        
        # ì§ë¬´ë³„ í•µì‹¬ ì—­ëŸ‰ í‚¤ì›Œë“œ
        self.job_competencies = {
            "ê°œë°œì": ["í”„ë¡œê·¸ë˜ë°", "ì•Œê³ ë¦¬ì¦˜", "ë°ì´í„°ë² ì´ìŠ¤", "í˜‘ì—…", "ë¬¸ì œí•´ê²°", "ë””ë²„ê¹…", "ì„¤ê³„", "í…ŒìŠ¤íŠ¸"],
            "ë§ˆì¼€íŒ…": ["ì‹œì¥ë¶„ì„", "ê¸°íš", "í”„ë¡œëª¨ì…˜", "ë°ì´í„°ë¶„ì„", "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜", "íŠ¸ë Œë“œ", "ì „ëµ", "ìº í˜ì¸"],
            "ì˜ì—…": ["í˜‘ìƒ", "ê³ ê°ê´€ë¦¬", "ëª©í‘œë‹¬ì„±", "í”„ë ˆì  í…Œì´ì…˜", "ë„¤íŠ¸ì›Œí‚¹", "ì‹œì¥ê°œì²™", "ê´€ê³„êµ¬ì¶•"],
            "ë””ìì¸": ["ì°½ì˜ì„±", "íˆ´í™œìš©", "UX", "UI", "íŠ¸ë Œë“œ", "ì»¨ì…‰", "ë¹„ì£¼ì–¼", "ì‚¬ìš©ìì¤‘ì‹¬"],
            "ê¸°íš": ["ë¶„ì„", "ì „ëµ", "í”„ë¡œì íŠ¸", "ë¬¸ì„œì‘ì„±", "ì¡°ì‚¬", "ì•„ì´ë””ì–´", "ì‹¤í–‰", "ê´€ë¦¬"]
        }
        
        # STAR ê¸°ë²• í‚¤ì›Œë“œ
        self.star_keywords = {
            "situation": ["ìƒí™©", "ë•Œ", "ë‹¹ì‹œ", "í™˜ê²½", "ë°°ê²½", "ì¡°ê±´", "ì‹œê¸°"],
            "task": ["ê³¼ì œ", "ëª©í‘œ", "ë¬¸ì œ", "í•´ê²°", "ê°œì„ ", "ë¯¸ì…˜", "ì„ë¬´", "ì±…ì„"],
            "action": ["ì‹¤í–‰", "ì§„í–‰", "ìˆ˜í–‰", "ë…¸ë ¥", "ì‹œë„", "ì ‘ê·¼", "ë°©ë²•", "í™œë™"],
            "result": ["ê²°ê³¼", "ì„±ê³¼", "ë‹¬ì„±", "ê°œì„ ", "í–¥ìƒ", "íš¨ê³¼", "ë³€í™”", "ì„±ê³µ"]
        }
        
        # AI í‹°ë‚˜ëŠ” í‘œí˜„ë“¤
        self.ai_cliches = [
            "ê·€ì‚¬", "ì €ëŠ” ë¯¿ìŠµë‹ˆë‹¤", "ì—´ì •ì ì¸", "ë„ì „ì •ì‹ ", "ì„±ì‹¤í•œ",
            "íŒ€ì›Œí¬", "ê¸ì •ì ì¸", "ì°½ì˜ì ì¸", "í˜ì‹ ì ì¸", "ê¸€ë¡œë²Œ",
            "ì‹œë„ˆì§€", "íŒ¨ëŸ¬ë‹¤ì„", "ë¹„ì „", "ë¯¸ì…˜", "í•µì‹¬ê°€ì¹˜"
        ]
        
    def analyze_response(self, response: str, position: str = None, 
                        conversation_history: List[Dict] = None) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì‘ë‹µ ì¢…í•© ë¶„ì„
        
        Args:
            response: ì‚¬ìš©ì ë‹µë³€
            position: ì§€ì› ì§ë¬´
            conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        results = {
            "quality_score": self.calculate_quality_score(response),
            "specificity": self.check_specificity(response),
            "star_compliance": self.check_star_compliance(response),
            "authenticity": self.check_authenticity(response),
            "keywords": self.extract_keywords(response),
            "competencies": self.extract_competencies(response, position),
            "improvement_tips": []
        }
        
        # ê°œì„  ì œì•ˆ ìƒì„±
        results["improvement_tips"] = self.generate_improvement_tips(results)
        
        # ì „ì²´ ëŒ€í™” ê¸°ë°˜ ë¶„ì„ (íˆìŠ¤í† ë¦¬ê°€ ìˆëŠ” ê²½ìš°)
        if conversation_history:
            results["conversation_analysis"] = self.analyze_conversation(
                conversation_history, position
            )
        
        return results
    
    def calculate_quality_score(self, response: str) -> Dict[str, float]:
        """
        ë‹µë³€ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        
        Returns:
            ê° í•­ëª©ë³„ ì ìˆ˜ (0-100)
        """
        scores = {
            "length": self._score_length(response),
            "specificity": self._score_specificity(response),
            "structure": self._score_structure(response),
            "uniqueness": self._score_uniqueness(response)
        }
        
        scores["overall"] = sum(scores.values()) / len(scores)
        return scores
    
    def _score_length(self, text: str) -> float:
        """ë‹µë³€ ê¸¸ì´ ì ìˆ˜"""
        word_count = len(text.split())
        if word_count < 30:
            return 30.0
        elif word_count < 50:
            return 50.0
        elif word_count < 150:
            return 80.0
        elif word_count < 300:
            return 100.0
        else:
            return 70.0  # ë„ˆë¬´ ê¸´ ë‹µë³€
    
    def _score_specificity(self, text: str) -> float:
        """êµ¬ì²´ì„± ì ìˆ˜"""
        score = 0.0
        
        # ìˆ«ì í¬í•¨ ì—¬ë¶€ (ê¸°ê°„, ì„±ê³¼ ë“±)
        if re.search(r'\d+', text):
            score += 30
        
        # êµ¬ì²´ì  ì‹œê°„ í‘œí˜„
        time_patterns = r'(ë…„|ê°œì›”|ì›”|ì£¼|ì¼|ì‹œê°„|ë¶„ê¸°|í•™ê¸°|íšŒ)'
        if re.search(time_patterns, text):
            score += 20
        
        # êµ¬ì²´ì  í–‰ë™ ë™ì‚¬
        action_verbs = ["ê°œë°œ", "ì‘ì„±", "ë¶„ì„", "ì„¤ê³„", "ê´€ë¦¬", "ì§„í–‰", "ìˆ˜í–‰", "ë‹¬ì„±"]
        for verb in action_verbs:
            if verb in text:
                score += 10
                if score >= 50:
                    break
        
        return min(score, 100.0)
    
    def _score_structure(self, text: str) -> float:
        """êµ¬ì¡° ì ìˆ˜ (STAR ê¸°ë²• ë“±)"""
        sentences = text.split('.')
        if len(sentences) < 3:
            return 30.0
        
        # ìˆœì°¨ì  êµ¬ì¡° ì²´í¬
        has_situation = any(kw in text for kw in ["ë‹¹ì‹œ", "ë•Œ", "ìƒí™©"])
        has_action = any(kw in text for kw in ["ìˆ˜í–‰", "ì§„í–‰", "ì‹¤í–‰", "í–ˆìŠµë‹ˆë‹¤"])
        has_result = any(kw in text for kw in ["ê²°ê³¼", "ì„±ê³¼", "ë‹¬ì„±"])
        
        score = 40.0
        if has_situation:
            score += 20
        if has_action:
            score += 20
        if has_result:
            score += 20
        
        return score
    
    def _score_uniqueness(self, text: str) -> float:
        """ë…ì°½ì„± ì ìˆ˜ (AI í´ë¦¬ì…° íšŒí”¼)"""
        score = 100.0
        
        # AI í´ë¦¬ì…° ì²´í¬
        for cliche in self.ai_cliches:
            if cliche in text:
                score -= 10
        
        return max(score, 0.0)
    
    def check_specificity(self, response: str) -> Dict[str, Any]:
        """êµ¬ì²´ì„± ìƒì„¸ ë¶„ì„"""
        return {
            "has_numbers": bool(re.search(r'\d+', response)),
            "has_timeframe": bool(re.search(r'(ë…„|ê°œì›”|ì›”|ì£¼|ì¼)', response)),
            "has_metrics": bool(re.search(r'(%|í¼ì„¼íŠ¸|ì¦ê°€|ê°ì†Œ|í–¥ìƒ)', response)),
            "has_examples": "ì˜ˆë¥¼" in response or "ê²½ìš°" in response,
            "score": self._score_specificity(response)
        }
    
    def check_star_compliance(self, response: str) -> Dict[str, Any]:
        """STAR ê¸°ë²• ì¤€ìˆ˜ ì—¬ë¶€ ì²´í¬"""
        compliance = {}
        
        for component, keywords in self.star_keywords.items():
            found = any(kw in response for kw in keywords)
            compliance[component] = found
        
        # ì „ì²´ ì¤€ìˆ˜ìœ¨
        compliance_rate = sum(compliance.values()) / len(compliance) * 100
        
        return {
            "components": compliance,
            "compliance_rate": compliance_rate,
            "missing": [k for k, v in compliance.items() if not v]
        }
    
    def check_authenticity(self, response: str) -> Dict[str, Any]:
        """ì§„ì •ì„± í‰ê°€ (AI í‹° ê²€ì‚¬)"""
        ai_score = 0
        detected_cliches = []
        
        for cliche in self.ai_cliches:
            if cliche in response:
                ai_score += 1
                detected_cliches.append(cliche)
        
        # ì§„ì •ì„± ì ìˆ˜ (AI í´ë¦¬ì…°ê°€ ì ì„ìˆ˜ë¡ ë†’ìŒ)
        authenticity_score = max(100 - (ai_score * 15), 0)
        
        return {
            "authenticity_score": authenticity_score,
            "detected_cliches": detected_cliches,
            "is_authentic": authenticity_score >= 70
        }
    
    def extract_keywords(self, response: str) -> List[str]:
        """í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if USE_KONLPY:
            # í˜•íƒœì†Œ ë¶„ì„ ì‚¬ìš©
            nouns = self.okt.nouns(response)
            # 2ê¸€ì ì´ìƒ ëª…ì‚¬ë§Œ í•„í„°ë§
            keywords = [noun for noun in nouns if len(noun) >= 2]
        else:
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê³µë°± ê¸°ì¤€)
            words = response.split()
            keywords = [w for w in words if len(w) >= 4]  # 4ê¸€ì ì´ìƒ
        
        # ë¹ˆë„ìˆ˜ ê¸°ì¤€ ìƒìœ„ 10ê°œ
        counter = Counter(keywords)
        return [kw for kw, _ in counter.most_common(10)]
    
    def extract_competencies(self, response: str, position: str = None) -> Dict[str, Any]:
        """ì—­ëŸ‰ ì¶”ì¶œ ë° ë§¤ì¹­"""
        found_competencies = []
        
        # ì§ë¬´ë³„ ì—­ëŸ‰ ì²´í¬
        if position:
            # ì§ë¬´ í‚¤ì›Œë“œ ë§¤ì¹­
            for job_type, competencies in self.job_competencies.items():
                if job_type in position:
                    for comp in competencies:
                        if comp in response:
                            found_competencies.append(comp)
                    break
        
        # ì¼ë°˜ ì—­ëŸ‰ ì²´í¬
        general_competencies = ["ë¦¬ë”ì‹­", "ì†Œí†µ", "í˜‘ì—…", "ë¬¸ì œí•´ê²°", "ì±…ì„ê°", "ë„ì „", "ì°½ì˜"]
        for comp in general_competencies:
            if comp in response:
                found_competencies.append(comp)
        
        return {
            "found": list(set(found_competencies)),
            "count": len(set(found_competencies)),
            "coverage": len(set(found_competencies)) / 5 * 100  # 5ê°œ ì´ìƒì´ ì´ìƒì 
        }
    
    def generate_improvement_tips(self, analysis_results: Dict) -> List[str]:
        """ê°œì„  ì œì•ˆ ìƒì„±"""
        tips = []
        
        # êµ¬ì²´ì„± ë¶€ì¡±
        if analysis_results["specificity"]["score"] < 50:
            tips.append("ğŸ’¡ êµ¬ì²´ì ì¸ ìˆ«ìë‚˜ ê¸°ê°„ì„ ì¶”ê°€í•´ë³´ì„¸ìš”. ì˜ˆ: '3ê°œì›” ë™ì•ˆ', '20% í–¥ìƒ'")
        
        # STAR ê¸°ë²• ë¯¸ì¤€ìˆ˜
        star = analysis_results["star_compliance"]
        if star["compliance_rate"] < 75:
            missing = star["missing"]
            if "situation" in missing:
                tips.append("ğŸ“ ì–´ë–¤ ìƒí™©ì´ì—ˆëŠ”ì§€ ë°°ê²½ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”")
            if "task" in missing:
                tips.append("ğŸ¯ í•´ê²°í•´ì•¼ í–ˆë˜ ê³¼ì œë‚˜ ëª©í‘œë¥¼ ëª…ì‹œí•´ì£¼ì„¸ìš”")
            if "action" in missing:
                tips.append("âš¡ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ í–‰ë™ì„ ì·¨í–ˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”")
            if "result" in missing:
                tips.append("ğŸ† ê·¸ ê²°ê³¼ ì–´ë–¤ ì„±ê³¼ë¥¼ ì–»ì—ˆëŠ”ì§€ ì¶”ê°€í•´ì£¼ì„¸ìš”")
        
        # ì§„ì •ì„± ë¶€ì¡±
        if analysis_results["authenticity"]["authenticity_score"] < 70:
            tips.append("âœ¨ ì¢€ ë” ìì—°ìŠ¤ëŸ½ê³  ê°œì¸ì ì¸ í‘œí˜„ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”")
        
        # ê¸¸ì´ ë¶€ì¡±
        if analysis_results["quality_score"]["length"] < 50:
            tips.append("ğŸ“ ì¡°ê¸ˆ ë” ìì„¸íˆ ì„¤ëª…í•´ì£¼ì‹œë©´ ì¢‹ê² ì–´ìš”")
        
        return tips
    
    def analyze_conversation(self, history: List[Dict], position: str = None) -> Dict[str, Any]:
        """ì „ì²´ ëŒ€í™” ë¶„ì„"""
        all_user_messages = [msg["content"] for msg in history if msg["role"] == "user"]
        full_text = " ".join(all_user_messages)
        
        # ì „ì²´ í‚¤ì›Œë“œ
        all_keywords = self.extract_keywords(full_text)
        
        # ì¼ê´€ì„± ì²´í¬ (ë°˜ë³µë˜ëŠ” í‚¤ì›Œë“œ)
        keyword_freq = Counter(all_keywords)
        consistent_themes = [kw for kw, freq in keyword_freq.items() if freq >= 2]
        
        # ì „ì²´ ì—­ëŸ‰ ì»¤ë²„ë¦¬ì§€
        all_competencies = self.extract_competencies(full_text, position)
        
        # ë°œì „ë„ (ë‹µë³€ì´ ì ì  êµ¬ì²´ì ì´ ë˜ëŠ”ì§€)
        quality_progression = []
        for msg in all_user_messages:
            score = self._score_specificity(msg)
            quality_progression.append(score)
        
        is_improving = False
        if len(quality_progression) >= 2:
            is_improving = quality_progression[-1] > quality_progression[0]
        
        return {
            "total_messages": len(all_user_messages),
            "consistent_themes": consistent_themes,
            "overall_competencies": all_competencies,
            "quality_progression": quality_progression,
            "is_improving": is_improving,
            "average_quality": sum(quality_progression) / len(quality_progression) if quality_progression else 0
        }


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    if len(sys.argv) < 2:
        print(json.dumps({
            "success": False,
            "error": "ì‚¬ìš©ë²•: python interactive_analyzer.py '<response_json>'"
        }))
        sys.exit(1)
    
    try:
        # JSON ì…ë ¥ íŒŒì‹±
        input_data = json.loads(sys.argv[1])
        
        response = input_data.get("response", "")
        position = input_data.get("position", None)
        history = input_data.get("conversation_history", [])
        
        # ë¶„ì„ ì‹¤í–‰
        analyzer = InteractiveAnalyzer()
        result = analyzer.analyze_response(response, position, history)
        
        # ê²°ê³¼ ì¶œë ¥
        output = {
            "success": True,
            "analysis": result
        }
        print(json.dumps(output, ensure_ascii=False, indent=2))
        
    except Exception as e:
        print(json.dumps({
            "success": False,
            "error": str(e)
        }, ensure_ascii=False))
        sys.exit(1)


if __name__ == "__main__":
    main()